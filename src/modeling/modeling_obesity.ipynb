{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597efedb",
   "metadata": {},
   "source": [
    "# Linear regression modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65187a0e",
   "metadata": {},
   "source": [
    "## Dataframe setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b1000b",
   "metadata": {},
   "source": [
    "Although our data was cleaned for the EDA section, some extra cleaning is required for running our model. Examples include, creating dummy variables as well as dropping columns with too many missing values as well as counties with missing values in any column. Below, we load in the required packages as well as clean as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad25996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7c00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in obesity data from our EDA and dropping columns that have too many null values. Additonally, hawaii and alaska\n",
    "# had no inputs for obesity rates which are necessary for our model. Thus, they were dropped. \n",
    "# furthermore, obesity proxies that went into creating healthy score access was also dropped.\n",
    "obesity_df = pd.read_csv(\"../../processed_data/obesity_eda.csv\")\n",
    "obesity_df[~obesity_df.region.str.contains('O')]\n",
    "obesity_df = obesity_df.drop(columns = ['primary_minority', 'supercenter_access_score', 'grocery_access_score', 'fullservice_access_score', 'farmersmarket_access_score', 'wic_available_per1000', 'snap_bens_per1000'])\n",
    "\n",
    "# Loading in car access data\n",
    "car_access_df = pd.read_csv(\"../../processed_data/car_access_2017.csv\")\n",
    "\n",
    "# Merged the two data sets\n",
    "obesity_df = pd.merge(obesity_df, car_access_df, how = 'left', on = 'fips')\n",
    "\n",
    "# made some numerical variables easier to read \n",
    "obesity_df['percent_no_car'] = obesity_df['percent_no_car'] * 100\n",
    "obesity_df['pop_estimate'] = obesity_df['pop_estimate']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d0af4",
   "metadata": {},
   "source": [
    "We wanted to find the counties within the contingous US that could be described as food desserts. One definition of  'food dessert', provided by the Annie E Casie foundation can be found [here](https://www.aecf.org/blog/exploring-americas-food-deserts),and other sources present a similar idea. The food insecurity variable in our data, obtained from Feeding America and coded as the fi_rate column, was calculated using many of the factors already described in the food insecurity definition found above; the calculation can be found [here](https://www.feedingamerica.org/sites/default/files/research/map-the-meal-gap/2016/2016-map-the-meal-gap-technical-brief.pdf). What was missing was a variable for access to food. Considering we had already created a proxy for access to food (healthy_access_category which encompasses grocery stores, supercenters, restaurants, and farmers markets), we decided to use both fi_rate and healthy_access_category to determine whether or not a county was labelled as being a food dessert.\n",
    "\n",
    "The third quartile for food insecurity is at about 15.200000 meaning 75 percent is at or below that value. We decided that any county in the highest 25% would be considered the 'highest tier' of food insecurity. We chose to take the top 25% because it is marginally conservative. We then decided too be food insecure, the county not only had to be within the top 25% of insecure counties in the United states but also have either low or medium access to healthy foods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899c6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making our food dessert categorical variable. \n",
    "conditions = [(obesity_df[\"fi_rate\"] > 15) & (obesity_df[\"healthy_access_category\"] != 'high'), \n",
    "              (obesity_df[\"fi_rate\"] <= 15)]\n",
    "values = [1, 0]\n",
    "\n",
    "obesity_df[\"food_dessert\"] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69ca077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping any remaining null values so our model can work\n",
    "obesity_df = obesity_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08001a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating dummy variables; the VIF test does not take in categorical variables\n",
    "\n",
    "obesity_df['region'] = obesity_df['region'].map({'N':1, 'M':2, 'S':3, 'W':4})\n",
    "obesity_df['healthy_access_category'] = obesity_df['healthy_access_category'].map({'low':1, 'medium':2, 'high':3})\n",
    "obesity_df['class_category'] = obesity_df['class_category'].map({'low_income':1, 'lower_mid_class':2, 'mid_class':3, 'highest_income': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264226cc",
   "metadata": {},
   "source": [
    "### Checking data to determine which variables do not have colinearity then running multivarable regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5b40e",
   "metadata": {},
   "source": [
    "In order to avoid multicollinearity, [independent values which have high correlation with eachother](https://towardsdatascience.com/multi-collinearity-in-regression-fe7a2c1467ea), we used the Variance Inflation Factor (VIF) technque. In the VIF method, all features are regressed against all of the other features. We only took variables with a VIF below 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12ccd5",
   "metadata": {},
   "source": [
    "#### Attempt 1: Running VIF on all columns followed by model (inefficent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbe4dc",
   "metadata": {},
   "source": [
    "In this first attempt, we took every column in our dataset and ran VIF on it. We then only put the variables with low VIF into the regression model. Following that, we removed variables one by one in the model if they did not have a significant p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40c26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all of our columns into a list\n",
    "indp_vars = obesity_df[['percent_pop_low_access_15',\n",
    "       'percent_low_income_low_access_15', 'percent_no_car_low_access_15',\n",
    "       'percent_snap_low_access_15', 'percent_child_low_access_15',\n",
    "       'percent_senior_low_access_15', 'percent_white_low_access_15',\n",
    "       'percent_black_low_access_15', 'percent_hispanic_low_access_15',\n",
    "       'percent_asian_low_access_15', 'percent_nhna_low_access_15',\n",
    "       'nhpi_low_access_15', 'percent_nhpi_low_access_15',\n",
    "       'percent_multiracial_low_access_15', 'grocery_per1000', 'super_per1000',\n",
    "       'convenience_per1000', 'specialty_per1000', 'snap_available_per1000',\n",
    "        'farmers_markets_per1000', 'pct_fm_accepting_snap',\n",
    "       'pct_fm_accept_wic', 'pct_fm_credit', 'fm_sell_frveg',\n",
    "       'pct_fm_sell_frveg', 'region','cost_per_meal', 'est_annual_food_budget_shortfall',\n",
    "       'school_lunch_prog_17', 'school_bfast_prog_17', 'smr_food_prog_17',\n",
    "       'wic_parts_pop_17', 'fast_food_per1000', 'full_service_per1000',\n",
    "       'pop_estimate', 'percent_white', 'percent_black',\n",
    "       'percent_native_american', 'percent_asian', 'percent_nhpi',\n",
    "       'percent_multi', 'percent_nonwhite_hispanic', 'median_household_income',\n",
    "       'class_category', 'healthy_access_score',\n",
    "       'healthy_access_category', 'percent_no_car', 'food_dessert']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac395c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/\n",
    "# creating a blank dataframe followed by adding each column to a new column called feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = indp_vars.columns\n",
    "\n",
    "# for every feature in vif_data, run VIF on it \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(indp_vars.values, i)\n",
    "                          for i in range(len(indp_vars.columns))]\n",
    "\n",
    "# filter the data to include VIF less than ten\n",
    "vif_data = vif_data[vif_data[\"VIF\"] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87fb4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           obesity_rate   R-squared:                       0.402\n",
      "Model:                            OLS   Adj. R-squared:                  0.398\n",
      "Method:                 Least Squares   F-statistic:                     107.5\n",
      "Date:                Sat, 17 Jul 2021   Prob (F-statistic):          1.77e-321\n",
      "Time:                        14:24:38   Log-Likelihood:                -8144.4\n",
      "No. Observations:                3062   AIC:                         1.633e+04\n",
      "Df Residuals:                    3042   BIC:                         1.645e+04\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                       31.1097      0.280    111.024      0.000      30.560      31.659\n",
      "percent_no_car_low_access_15    36.1745      3.395     10.655      0.000      29.518      42.831\n",
      "grocery_per1000                 -0.1250      0.393     -0.318      0.751      -0.896       0.646\n",
      "super_per1000                   18.0785      3.065      5.899      0.000      12.069      24.088\n",
      "convenience_per1000              1.7322      0.245      7.057      0.000       1.251       2.213\n",
      "specialty_per1000               -2.6634      0.897     -2.969      0.003      -4.423      -0.904\n",
      "farmers_markets_per1000         -0.3442      0.758     -0.454      0.650      -1.829       1.141\n",
      "pct_fm_accepting_snap         9.687e-05      0.003      0.038      0.970      -0.005       0.005\n",
      "pct_fm_accept_wic               -0.0005      0.002     -0.198      0.843      -0.005       0.004\n",
      "pct_fm_credit                   -0.0129      0.002     -5.362      0.000      -0.018      -0.008\n",
      "fm_sell_frveg                   -0.1273      0.020     -6.456      0.000      -0.166      -0.089\n",
      "pct_fm_sell_frveg                0.0054      0.002      2.355      0.019       0.001       0.010\n",
      "smr_food_prog_17                 0.0413      0.030      1.383      0.167      -0.017       0.100\n",
      "fast_food_per1000               -0.0002      0.254     -0.001      0.999      -0.498       0.497\n",
      "full_service_per1000            -2.1155      0.151    -13.974      0.000      -2.412      -1.819\n",
      "percent_native_american          0.0263      0.010      2.590      0.010       0.006       0.046\n",
      "percent_asian                   -0.3456      0.034    -10.043      0.000      -0.413      -0.278\n",
      "percent_nhpi                    -0.7796      0.365     -2.139      0.033      -1.494      -0.065\n",
      "percent_multi                   -0.7519      0.134     -5.624      0.000      -1.014      -0.490\n",
      "food_dessert                     1.7169      0.172     10.011      0.000       1.381       2.053\n",
      "==============================================================================\n",
      "Omnibus:                       91.627   Durbin-Watson:                   1.383\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              125.360\n",
      "Skew:                          -0.325   Prob(JB):                     6.00e-28\n",
      "Kurtosis:                       3.749   Cond. No.                     4.91e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.91e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# code was modeled and influenced by DS4A (Correlation One) material\n",
    "formula= 'obesity_rate ~  percent_no_car_low_access_15 + grocery_per1000+ super_per1000+convenience_per1000+ specialty_per1000+farmers_markets_per1000+ pct_fm_accepting_snap+pct_fm_accept_wic+ pct_fm_credit+ fm_sell_frveg+pct_fm_sell_frveg+ smr_food_prog_17+ fast_food_per1000+full_service_per1000+ percent_native_american+ percent_asian+percent_nhpi+ percent_multi+ food_dessert'\n",
    "model1 = sm.ols(formula = formula, data = obesity_df)\n",
    "lin_reg = model1.fit()\n",
    "print(lin_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223406e3",
   "metadata": {},
   "source": [
    "#### Running VIS on columns thoght to have relevance in literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a545b",
   "metadata": {},
   "source": [
    "In this second attempt, we took only columns in our dataset that had some evidence in the literature of having an effecton obesitynand ran VIF on it. We then only put the variables with low VIF into the regression model. Following that, we removed variables one by one in the model if they did not have a significant p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f573c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making our food dessert categorical variable. \n",
    "indp_vars2 = obesity_df[[ 'grocery_per1000', 'super_per1000',\n",
    "       'convenience_per1000', 'snap_available_per1000','fast_food_per1000', 'full_service_per1000',\n",
    "       'farmers_markets_per1000', 'cost_per_meal', 'smr_food_prog_17', 'pop_estimate', 'percent_white', 'percent_black',\n",
    "       'percent_native_american', 'percent_asian', 'percent_nhpi',\n",
    "       'percent_multi', 'percent_nonwhite_hispanic', 'food_dessert', 'school_lunch_prog_17', 'school_bfast_prog_17']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709bc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/\n",
    "# creating a blank dataframe followed by adding each column to a new column called feature\n",
    "vif_data2 = pd.DataFrame()\n",
    "vif_data2[\"feature\"] = indp_vars2.columns\n",
    "\n",
    "# for every feature in vif_data, run VIF on it \n",
    "vif_data2[\"VIF\"] = [variance_inflation_factor(indp_vars2.values, i)\n",
    "                          for i in range(len(indp_vars2.columns))]\n",
    "\n",
    "# filter the data to include VIF less than ten\n",
    "vif_data2 = vif_data2[vif_data2[\"VIF\"] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "579d08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "train, test = model_selection.train_test_split(obesity_df, train_size=0.80, random_state=88)\n",
    "\n",
    "Train = pd.DataFrame(train, columns=obesity_df.columns)\n",
    "Test = pd.DataFrame(test, columns=obesity_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e74e2d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           obesity_rate   R-squared:                       0.422\n",
      "Model:                            OLS   Adj. R-squared:                  0.419\n",
      "Method:                 Least Squares   F-statistic:                     127.1\n",
      "Date:                Sat, 17 Jul 2021   Prob (F-statistic):          2.22e-277\n",
      "Time:                        14:24:38   Log-Likelihood:                -6479.8\n",
      "No. Observations:                2449   AIC:                         1.299e+04\n",
      "Df Residuals:                    2434   BIC:                         1.308e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    32.1442      0.296    108.642      0.000      31.564      32.724\n",
      "super_per1000                16.7439      3.256      5.142      0.000      10.359      23.129\n",
      "convenience_per1000           1.8865      0.270      6.983      0.000       1.357       2.416\n",
      "fast_food_per1000            -0.6238      0.269     -2.323      0.020      -1.150      -0.097\n",
      "full_service_per1000         -2.3851      0.149    -15.993      0.000      -2.678      -2.093\n",
      "farmers_markets_per1000      -0.3992      0.784     -0.509      0.611      -1.937       1.139\n",
      "smr_food_prog_17             -0.0320      0.032     -0.990      0.322      -0.095       0.031\n",
      "pop_estimate                 -0.0011      0.000     -4.114      0.000      -0.002      -0.001\n",
      "percent_black                 0.0809      0.006     12.990      0.000       0.069       0.093\n",
      "percent_native_american       0.0626      0.011      5.475      0.000       0.040       0.085\n",
      "percent_asian                -0.4435      0.037    -11.976      0.000      -0.516      -0.371\n",
      "percent_nhpi                 -0.5007      0.384     -1.304      0.192      -1.253       0.252\n",
      "percent_multi                -0.2834      0.143     -1.981      0.048      -0.564      -0.003\n",
      "percent_nonwhite_hispanic    -0.0453      0.006     -8.178      0.000      -0.056      -0.034\n",
      "food_dessert                  0.7828      0.209      3.737      0.000       0.372       1.194\n",
      "==============================================================================\n",
      "Omnibus:                       80.939   Durbin-Watson:                   1.885\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              128.121\n",
      "Skew:                          -0.301   Prob(JB):                     1.51e-28\n",
      "Kurtosis:                       3.945   Cond. No.                     1.61e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.61e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# code was modeled and influenced by DS4A (Correlation One) material\n",
    "formula2= 'obesity_rate ~ super_per1000+ convenience_per1000+fast_food_per1000+ full_service_per1000+farmers_markets_per1000+ smr_food_prog_17+ pop_estimate+percent_black+ percent_native_american+ percent_asian+percent_nhpi+ percent_multi+ percent_nonwhite_hispanic+food_dessert'\n",
    "model2 = sm.ols(formula = formula2, data = Train)\n",
    "lin_reg2 = model2.fit()\n",
    "print(lin_reg2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974367c",
   "metadata": {},
   "source": [
    "Looks like our second model would have (p = .01)\n",
    "    - supercenter\n",
    "    - convenience stores\n",
    "    - fast food\n",
    "    - full service restaurants\n",
    "    - population\n",
    "    - race factors (black, native, asian, hispanic) \n",
    "    - food dessert\n",
    "    - population\n",
    "    \n",
    "    Total = 11 variables, 12 if chose a p value of .05\n",
    "    \n",
    "if it was .05 then only addition is summer food programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791b179",
   "metadata": {},
   "source": [
    "## Fitting and testing models with Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965de0f",
   "metadata": {},
   "source": [
    "Sklearn also allows us to create our regression model. It gives less statistical information in comparison to statsmodels; however, it has several methods of testing the accuracy of our model. Understanding and creation of the code below is in large part a thanks to the articles written by [Scott Robinson](https://stackabuse.com/linear-regression-in-python-with-scikit-learn) and [Deepika Singh](https://www.pluralsight.com/guides/validating-machine-learning-models-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75580eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4874ec2",
   "metadata": {},
   "source": [
    "### Model 1 with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07285ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "obesity_df2 = obesity_df.copy().dropna()\n",
    "obesity_df2 = obesity_df2[['super_per1000', 'convenience_per1000','fast_food_per1000', 'full_service_per1000','farmers_markets_per1000', 'smr_food_prog_17', 'pop_estimate','percent_black', 'percent_native_american', 'percent_asian','percent_nhpi', 'percent_multi', 'percent_nonwhite_hispanic','food_dessert', 'obesity_rate']]\n",
    "x1 = obesity_df2.drop('obesity_rate', axis=1).values \n",
    "y1 = obesity_df2['obesity_rate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32885e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.75%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(x1, y1, test_size=0.20, random_state=100)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b253d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.10%\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits= 3)\n",
    "model_kfold = LinearRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, x1, y1, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c948992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>613.000000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.255465</td>\n",
       "      <td>31.026476</td>\n",
       "      <td>0.228989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.544715</td>\n",
       "      <td>2.644108</td>\n",
       "      <td>3.339614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.400000</td>\n",
       "      <td>20.933228</td>\n",
       "      <td>-12.104994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>29.643227</td>\n",
       "      <td>-1.965399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.200000</td>\n",
       "      <td>30.912940</td>\n",
       "      <td>0.570538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>32.134648</td>\n",
       "      <td>2.512459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>40.262339</td>\n",
       "      <td>8.329002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Actual   Predicted         off\n",
       "count  613.000000  613.000000  613.000000\n",
       "mean    31.255465   31.026476    0.228989\n",
       "std      4.544715    2.644108    3.339614\n",
       "min     16.400000   20.933228  -12.104994\n",
       "25%     28.800000   29.643227   -1.965399\n",
       "50%     31.200000   30.912940    0.570538\n",
       "75%     33.900000   32.134648    2.512459\n",
       "max     46.600000   40.262339    8.329002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': Y_test, 'Predicted': y_pred})\n",
    "df['off'] = df['Actual'] - df['Predicted']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e38c16",
   "metadata": {},
   "source": [
    "### Model 2 with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c68b4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obesity_df3 = obesity_df.copy()\n",
    "obesity_df3 = obesity_df3[['grocery_per1000', 'super_per1000','obesity_rate',\n",
    "       'convenience_per1000', 'snap_available_per1000','fast_food_per1000', 'full_service_per1000',\n",
    "       'farmers_markets_per1000', 'cost_per_meal', 'smr_food_prog_17', 'pop_estimate', 'percent_white', 'percent_black',\n",
    "       'percent_native_american', 'percent_asian', 'percent_nhpi',\n",
    "       'percent_multi', 'percent_nonwhite_hispanic', 'food_dessert', 'school_lunch_prog_17', 'school_bfast_prog_17']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3855a34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.81%\n"
     ]
    }
   ],
   "source": [
    "x2 = obesity_df3.drop('obesity_rate', axis=1).values \n",
    "y2 = obesity_df3['obesity_rate'].values\n",
    "\n",
    "X2_train, X2_test, Y2_train, Y2_test = model_selection.train_test_split(x2, y2, test_size=0.20, random_state=100)\n",
    "model = LinearRegression()\n",
    "model.fit(X2_train, Y2_train)\n",
    "result = model.score(X2_test, Y2_test)\n",
    "print(\"Accuracy: %.2f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0657e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.26%\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits= 3)\n",
    "model_kfold = LinearRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, x2, y2, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d61dca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>613.000000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.255465</td>\n",
       "      <td>31.029891</td>\n",
       "      <td>0.225574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.544715</td>\n",
       "      <td>3.105654</td>\n",
       "      <td>3.012616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.400000</td>\n",
       "      <td>19.881809</td>\n",
       "      <td>-10.668817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>29.202480</td>\n",
       "      <td>-1.682193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.200000</td>\n",
       "      <td>31.174336</td>\n",
       "      <td>0.375088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>32.602155</td>\n",
       "      <td>2.344844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>41.957531</td>\n",
       "      <td>8.498632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Actual   Predicted         off\n",
       "count  613.000000  613.000000  613.000000\n",
       "mean    31.255465   31.029891    0.225574\n",
       "std      4.544715    3.105654    3.012616\n",
       "min     16.400000   19.881809  -10.668817\n",
       "25%     28.800000   29.202480   -1.682193\n",
       "50%     31.200000   31.174336    0.375088\n",
       "75%     33.900000   32.602155    2.344844\n",
       "max     46.600000   41.957531    8.498632"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_pred = model.predict(X2_test)\n",
    "df2 = pd.DataFrame({'Actual': Y2_test, 'Predicted': y2_pred})\n",
    "df2['off'] = df2['Actual'] - df2['Predicted']\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff866f5",
   "metadata": {},
   "source": [
    "### Model 3 with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5bedcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obesity_df4 = obesity_df.copy()\n",
    "obesity_df4 = obesity_df4[['percent_no_car_low_access_15', 'percent_hispanic_low_access_15',\n",
    "       'percent_asian_low_access_15', 'nhpi_low_access_15',\n",
    "       'percent_nhpi_low_access_15', 'grocery_per1000', 'super_per1000',\n",
    "       'convenience_per1000', 'specialty_per1000',\n",
    "       'farmers_markets_per1000', 'pct_fm_accepting_snap',\n",
    "       'pct_fm_accept_wic', 'pct_fm_credit', 'fm_sell_frveg',\n",
    "       'pct_fm_sell_frveg', 'smr_food_prog_17', 'fast_food_per1000',\n",
    "       'full_service_per1000', 'percent_native_american', 'percent_asian',\n",
    "       'percent_nhpi', 'percent_multi', 'food_dessert', 'obesity_rate']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8e293e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.00%\n"
     ]
    }
   ],
   "source": [
    "x3 = obesity_df4.drop('obesity_rate', axis=1).values \n",
    "y3 = obesity_df4['obesity_rate'].values\n",
    "\n",
    "X3_train, X3_test, Y3_train, Y3_test = model_selection.train_test_split(x3, y3, test_size=0.20, random_state=100)\n",
    "model = LinearRegression()\n",
    "model.fit(X3_train, Y3_train)\n",
    "result = model.score(X3_test, Y3_test)\n",
    "print(\"Accuracy: %.2f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d5de6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.25%\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits= 3)\n",
    "model_kfold = LinearRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, x3, y3, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2dc45f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>613.000000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.255465</td>\n",
       "      <td>31.026496</td>\n",
       "      <td>0.228969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.544715</td>\n",
       "      <td>2.691547</td>\n",
       "      <td>3.453515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.400000</td>\n",
       "      <td>18.932068</td>\n",
       "      <td>-11.543924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>29.427124</td>\n",
       "      <td>-1.735934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.200000</td>\n",
       "      <td>31.053945</td>\n",
       "      <td>0.355401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>32.708653</td>\n",
       "      <td>2.517341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>40.479360</td>\n",
       "      <td>12.475967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Actual   Predicted         off\n",
       "count  613.000000  613.000000  613.000000\n",
       "mean    31.255465   31.026496    0.228969\n",
       "std      4.544715    2.691547    3.453515\n",
       "min     16.400000   18.932068  -11.543924\n",
       "25%     28.800000   29.427124   -1.735934\n",
       "50%     31.200000   31.053945    0.355401\n",
       "75%     33.900000   32.708653    2.517341\n",
       "max     46.600000   40.479360   12.475967"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_pred = model.predict(X3_test)\n",
    "df3 = pd.DataFrame({'Actual': Y3_test, 'Predicted': y3_pred})\n",
    "df3['off'] = df3['Actual'] - df3['Predicted']\n",
    "df3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014839ab",
   "metadata": {},
   "source": [
    "## Predicting obesity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ada2bd",
   "metadata": {},
   "source": [
    "#### based on model two from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25f15857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241428a3",
   "metadata": {},
   "source": [
    "Here we used the second linear regression model (found above) to predict obesity rate based on new input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc68a17e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                    32.144153\n",
       "super_per1000                16.743927\n",
       "convenience_per1000           1.886535\n",
       "fast_food_per1000            -0.623807\n",
       "full_service_per1000         -2.385076\n",
       "farmers_markets_per1000      -0.399200\n",
       "smr_food_prog_17             -0.031962\n",
       "pop_estimate                 -0.001051\n",
       "percent_black                 0.080931\n",
       "percent_native_american       0.062605\n",
       "percent_asian                -0.443510\n",
       "percent_nhpi                 -0.500720\n",
       "percent_multi                -0.283441\n",
       "percent_nonwhite_hispanic    -0.045263\n",
       "food_dessert                  0.782807\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the coefficents of the variables in the model\n",
    "lin_reg2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78c39713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>percent_pop_low_access_15</th>\n",
       "      <th>percent_low_income_low_access_15</th>\n",
       "      <th>percent_no_car_low_access_15</th>\n",
       "      <th>percent_snap_low_access_15</th>\n",
       "      <th>percent_child_low_access_15</th>\n",
       "      <th>percent_senior_low_access_15</th>\n",
       "      <th>percent_white_low_access_15</th>\n",
       "      <th>...</th>\n",
       "      <th>percent_nhpi</th>\n",
       "      <th>percent_multi</th>\n",
       "      <th>percent_nonwhite_hispanic</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>obesity_category</th>\n",
       "      <th>class_category</th>\n",
       "      <th>healthy_access_score</th>\n",
       "      <th>healthy_access_category</th>\n",
       "      <th>percent_no_car</th>\n",
       "      <th>food_dessert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>58343.0</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>56607.0</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>32490.0</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>45795.0</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48253.0</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>56037</td>\n",
       "      <td>WY</td>\n",
       "      <td>Sweetwater</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>75590.0</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>56039</td>\n",
       "      <td>WY</td>\n",
       "      <td>Teton</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90145.0</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>56041</td>\n",
       "      <td>WY</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>67404.0</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>56043</td>\n",
       "      <td>WY</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>57989.0</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>56045</td>\n",
       "      <td>WY</td>\n",
       "      <td>Weston</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>56214.0</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3062 rows  55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fips state      county  percent_pop_low_access_15  \\\n",
       "0      1001    AL     Autauga                       0.32   \n",
       "1      1003    AL     Baldwin                       0.17   \n",
       "2      1005    AL     Barbour                       0.22   \n",
       "3      1007    AL        Bibb                       0.04   \n",
       "4      1009    AL      Blount                       0.06   \n",
       "...     ...   ...         ...                        ...   \n",
       "3097  56037    WY  Sweetwater                       0.43   \n",
       "3098  56039    WY       Teton                       0.29   \n",
       "3099  56041    WY       Uinta                       0.22   \n",
       "3100  56043    WY    Washakie                       0.11   \n",
       "3101  56045    WY      Weston                       0.17   \n",
       "\n",
       "      percent_low_income_low_access_15  percent_no_car_low_access_15  \\\n",
       "0                                 0.12                          0.03   \n",
       "1                                 0.05                          0.02   \n",
       "2                                 0.11                          0.04   \n",
       "3                                 0.03                          0.03   \n",
       "4                                 0.03                          0.03   \n",
       "...                                ...                           ...   \n",
       "3097                              0.11                          0.02   \n",
       "3098                              0.07                          0.01   \n",
       "3099                              0.10                          0.03   \n",
       "3100                              0.04                          0.01   \n",
       "3101                              0.04                          0.04   \n",
       "\n",
       "      percent_snap_low_access_15  percent_child_low_access_15  \\\n",
       "0                           0.05                         0.08   \n",
       "1                           0.01                         0.04   \n",
       "2                           0.04                         0.04   \n",
       "3                           0.01                         0.01   \n",
       "4                           0.01                         0.02   \n",
       "...                          ...                          ...   \n",
       "3097                        0.02                         0.11   \n",
       "3098                        0.01                         0.05   \n",
       "3099                        0.02                         0.07   \n",
       "3100                        0.01                         0.02   \n",
       "3101                        0.01                         0.04   \n",
       "\n",
       "      percent_senior_low_access_15  percent_white_low_access_15  ...  \\\n",
       "0                             0.04                         0.23  ...   \n",
       "1                             0.03                         0.14  ...   \n",
       "2                             0.03                         0.10  ...   \n",
       "3                             0.01                         0.02  ...   \n",
       "4                             0.01                         0.06  ...   \n",
       "...                            ...                          ...  ...   \n",
       "3097                          0.04                         0.38  ...   \n",
       "3098                          0.03                         0.27  ...   \n",
       "3099                          0.02                         0.20  ...   \n",
       "3100                          0.03                         0.10  ...   \n",
       "3101                          0.03                         0.17  ...   \n",
       "\n",
       "      percent_nhpi  percent_multi  percent_nonwhite_hispanic  \\\n",
       "0              0.1            0.4                        2.7   \n",
       "1              0.0            0.4                        4.4   \n",
       "2              0.0            0.3                        4.2   \n",
       "3              0.0            0.5                        2.4   \n",
       "4              0.0            0.4                        9.0   \n",
       "...            ...            ...                        ...   \n",
       "3097           0.5            0.6                       16.0   \n",
       "3098           0.0            0.6                       15.0   \n",
       "3099           0.0            0.9                        9.1   \n",
       "3100           0.0            1.1                       14.2   \n",
       "3101           0.0            1.6                        1.4   \n",
       "\n",
       "      median_household_income  obesity_category  class_category  \\\n",
       "0                     58343.0              high               3   \n",
       "1                     56607.0               med               3   \n",
       "2                     32490.0              high               1   \n",
       "3                     45795.0              high               2   \n",
       "4                     48253.0              high               2   \n",
       "...                       ...               ...             ...   \n",
       "3097                  75590.0               med               3   \n",
       "3098                  90145.0               low               3   \n",
       "3099                  67404.0               med               3   \n",
       "3100                  57989.0               med               3   \n",
       "3101                  56214.0               med               3   \n",
       "\n",
       "      healthy_access_score  healthy_access_category  percent_no_car  \\\n",
       "0                        7                        2            5.41   \n",
       "1                        9                        2            3.35   \n",
       "2                        9                        2            9.63   \n",
       "3                        8                        2            5.70   \n",
       "4                        6                        1            4.14   \n",
       "...                    ...                      ...             ...   \n",
       "3097                     7                        2            2.97   \n",
       "3098                    10                        3            1.65   \n",
       "3099                    10                        3            4.21   \n",
       "3100                    10                        3            5.85   \n",
       "3101                    10                        3            5.06   \n",
       "\n",
       "      food_dessert  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "3097             0  \n",
       "3098             0  \n",
       "3099             0  \n",
       "3100             0  \n",
       "3101             0  \n",
       "\n",
       "[3062 rows x 55 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee052e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Here we ask the user for new input variables. However, we do not allow racial makeup to be changed due to \n",
    "# negative implications. \n",
    "\n",
    "fips = float(input())\n",
    "super_input = float(input())\n",
    "convenience_store = float(input())\n",
    "fast_food = float(input())\n",
    "restaurant = float(input())\n",
    "farmers_market = float(input())\n",
    "summer_prog = float(input())\n",
    "population = obesity_df.loc[obesity_df['fips'] == fips, 'pop_estimate'].iloc[0]\n",
    "black = obesity_df.loc[obesity_df['fips'] == fips, 'percent_black'].iloc[0]\n",
    "native = obesity_df.loc[obesity_df['fips'] == fips, 'percent_native_american'].iloc[0]\n",
    "asian = obesity_df.loc[obesity_df['fips'] == fips, 'percent_asian'].iloc[0]\n",
    "nhpi = obesity_df.loc[obesity_df['fips'] == fips, 'percent_nhpi'].iloc[0]\n",
    "multi = obesity_df.loc[obesity_df['fips'] == fips, 'percent_multi'].iloc[0]\n",
    "hisp = obesity_df.loc[obesity_df['fips'] == fips, 'percent_nonwhite_hispanic'].iloc[0]\n",
    "food_des = obesity_df.loc[obesity_df['fips'] == fips, 'food_dessert'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cbee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then create a new dataframe with the variables above so we can input it into the model prediction\n",
    "new_vals = pd.DataFrame({'super_per1000': [super_input], 'convenience_per1000': [convenience_store],'fast_food_per1000': [fast_food], 'full_service_per1000': [restaurant], 'farmers_markets_per1000': [farmers_market], 'smr_food_prog_17': [summer_prog], 'pop_estimate': [population], 'percent_black': [black],'percent_native_american': [native],'percent_asian': [asian], 'percent_nhpi': [nhpi], 'percent_multi': [multi], 'percent_nonwhite_hispanic': [hisp], 'food_dessert': [food_des]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b38c8aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    48.156464\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the new variables are put into the new model and then the second value is the predicted obesity in the county based upon changes\n",
    "xnew = sm.add_constant(new_vals)\n",
    "ynewpred =  lin_reg2.predict(xnew)\n",
    "ynewpred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
